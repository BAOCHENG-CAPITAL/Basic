# 过拟合和欠拟合

机器学习模型构建的目标是能够基于有限的训练集样本，学习到数据特征与预测标签之间真正的关系，最终使该模型能够在新的测试样本中获得较好的预测效果。为了达到这个目标，我们应该尽可能让模型去注意到潜在样本的“一般规律”，使模型能够举一反三，而不是去记住所有训练集的细节。如果模型在学习样本时，学习得太好了，在训练集中学习到了过多的细节并取得了出色的表现，这可能会导致模型在面临一个新的数据集时，预测结果非常差。

奥卡姆剃刀定律也是对于过拟合问题的一个很好表述：“如无必要，勿增实体”，即"简单有效原理"。

过拟合问题出现的原因是模型对巡礼拿数据产生了过度拟合，错误地把训练数据中的噪声当成有效信息，当样本外数据中不存在训练数据中的噪声时，模型往往找不到有效信息，导致样本外预测结果差。过拟合问题最明显的特征就是，模型在训练集上表现优秀，但是在样本外的测试集上表现非常差。过拟合问题的发生往往是伴随着选择使用更加灵活或者复杂的模型，如决策树、神经网络等非常灵活的模型。与过拟合相对应的就是欠拟合问题，它是指模型对训练数据拟合得不好、对于新的数据也拟合不好的情况.

常用的过拟合问题的解决方案一般有以下几种.

1. 增加更多的数据.在机器学习算法中,有的时候数据的重要性会高于模型.我们在用训练集数据进行训练时,往往会假设训练数据与将来的数据是独立同分布的,只有训练数据更多,才能更好地使得训练集中的数据更加逼近真实的数据分布,获得更好的效果
2. 降低模型复杂度.机器学习中经常使用正则化 剪枝等方法来强制降低模型的复杂度,尽可能选择用一个偏简单的模型来建模
3. 集成算法.集成算法的核心思想是构建多个模型,然后通过一定策略把它们结合来完成学习任务的,常常可以获得比单一学习显著优越的学习器.
4. 主动丢失一些信息.在神经网络的dropout技术和随机森林的特征随机选择中都有用到这个方法
5. 使用交叉验证的方式.这点很重要.

相比过拟合来说,欠拟合问题更加容易解决,一般来说只需要增加模型复杂度即可.如果使用了很复杂的模型,训练集的表现还是非常糟糕,表现出欠拟合的情况,你应该检查一下数据的特征工程是否有问题,是否你的样本特征完全无法解释的标签变量导致,应该考虑增加新的有解释能力的特征变量.

# 偏差和方差的权衡

为了更好地理解过拟合的问题,可以进一步对训练集误差进行偏差和方差的拆解.假设存在一个真实的函数描绘了y与x之间的关系.机器学习的任务是要基于目前有的训练集数据T,寻找一个最优的widehatfT,使得其尽可能地与真实的函数f近似,一般来说,这个widehatfT函数必然会与真实的函数f存在偏离,这个偏离误差可以分为三个部分:偏差 方差和必然存在地误差项.

1. 偏差的本质是来源于模型选择的误差.
2. 方差的本质是来源于随机选择训练集数据T带来的偏差
3. 必然存在的误差项本质来源于可能模型本身就由一些不可被预测的随机误差项构成.在机器学习任务中,你永远不可能获得所有的样本,因此目前能够观测到的训练集T本身就具有随机性,根据有偏的训练集,就算训练出来最优模型,这个模型也永远无法和真实的函数f一样.为了更加严谨理解这三项误差,我们从数学上对上述问题进行定义和证明.

## 模型训练误差

在回归问题中,一般使用均方误差mean squared error,MSE大小来定义模型的好坏.它定义了我们训练好的模型widehatfT预测结果与真实函数f之间的欧式距离.即训练集的MSE由
$$
MSE(x)=E_T[(\widehat{f}_T(x)-f(x))^2]
$$
ET代表来自不同的训练集的平均值(期望值),我们定义不同训练集预测结果的平均值用miux表示
$$
\mu(x)=E_T[\widehat{f}_T(x)]
$$

1. 偏差的定义

   偏差是认为选取模型时带来的误差,它描述了训练集拟合出来模型的预测结果平均值与样本真实结果平均值的距离,数学上等于使用模型在训练集预测结果的平均值减去真实样本的平均值.
   $$
   Bias(x)=E_T[\widehat{f}_T(x)-f(x)]=\mu(x)-f(x)
   $$

2. 方差的定义

   方差是随机不同的训练集带来的偏离误差,它可以用统计学中方差的概念进行度量,即方差等于平均训练集预测结果与训练集预测结果的平均值之差的平方,用公式可以表示为
   $$
   \begin{align}
   Var(x)&=E_T[(\widehat{f}_T(x)-\mu(x))^2]\\
   &=E_T[(\widehat{f}_T(x)-2\widehat{f}_T(x)\mu(x)+\mu(x)^2)]\\
   &=E_T[\widehat{f}_T(x)^2]-E_T[2\widehat{f}_T(x)\mu(x)]+E_T[\mu(x)^2]\\
   &=E_T[\widehat{f}_T(x)^2]-\mu(x)^2
   \end{align}
   $$
   

3. 训练误差的拆解证明

   定义好了偏差和方差之后,很容易将上面的训练误差进行拆解,证明过程如下
   $$
   \begin{align}
   MSE(x)&=E_T[(\widehat{f}_T(x)-f(x))^2]\\
   &=E_T[\widehat{f}_T(x)^2-2\widehat{f}_T(x)f(x)+f(x)^2]\\
   &=E_T[\widehat{f}_T(x)^2]-2\mu(x)f(x)+f(x)^2\\
   &=E_T[\widehat{f}_T(x)^2]-\mu(x)^2+\mu(x)^2-2\mu(x)f(x)+f(x)^2\\
   &=E_T[\widehat(f)_T(x)^2]-\mu(x)^2+(\mu(x)-f(x))^2\\
   &=Var(x)+Bias(x)^2
   \end{align}
   $$

4. 

## 偏差与方差权衡说明

从以上分析中可以看到,任何一个训练模型误差,都可以被拆分为偏差和方差两个部分,那么什么样的模型才是我们的目标呢?进一步基于以下打靶图片来说明模型训练的目标,每一个基于训练集训练好的模型都可以看成对完美模型的近似尝试.

这个近似过程跟运动员射击很像,如果你是一个射击教练,下面4个打靶成绩来自你手下的4名队员,你应该如何提升4名队员的成绩呢?

1. 高偏差和高方差的状态.

   这名队员显然射击能力很差,完全无法打中靶心,建议这名队员全方位提升或直接劝退才行.对应到机器学习的案例中,你训练好了一个模型,但是在不同的样本上,都表现非常差,而且每次预测的结果也千差万别.这种情况下,一般是你的模型不适合目前数据集,可以直接换模型或者加强特征工程.

2. 高方差和低偏差的状态.

   这名运动队员显然设计能力还行,有的时候能够打到靶心,有的时候偏得很远,建议这名队员加强稳定性.对应到机器学习的案例中,你训练好了一个模型,但是在不同的样本上,有一些样本表现非常好,有一些样本却表现非常差,而且每次预测的结果非常不稳定.这种情况下,也对应着前面讲过的过拟合问题,一般是由于模型过度复杂导致.

3. 高偏差和低方差的状态.

   这名队员显然射击能力一般,虽然完全打不中靶心,但是成绩非常稳定,建议这名队员瞄得准一些.对应到机器学习的案例中,你训练好了一个模型,在不同的样本上,对不同样本都表现非常一般,但是每次预测的结果非常稳定,这种情况下,也对应着前面讲过的欠拟合问题,一般是由于模型太简单导致.

4. 低偏差和低方差的状态.

   这名队员显然射击能力非常好,每次都打到靶心,而且成绩非常稳定,建议这名队员直接参加比赛.对应到机器学习的案例中,这个就是我们追求的理想的机器学习训练目标

## 模型复杂度与方差和偏差

前面的说明中,我们提到了模型复杂度影响着模型的泛化误差.

1. 从总误差来说,随着更复杂模型的使用,总误差先下降后上升.
2. 从偏差来说,随着更复杂模型的使用,偏差会一直下降.前面也提到,偏差来源于认为主观选择不同模型的误差,随着我们从使用最简单的线性模型.到使用那些最灵活什么函数形式都不限制的神经网络模型,能够获得的偏差会逐渐降低
3. 从方差来说,随着更复杂模型的使用,方差会一直上升.随着我们从使用最简单的线性模型,到使用那些最灵活什么函数形式都不限制的神经网络模型,获得的方差误差会逐渐上升.我们要追求的最优模型,是模型总误差处于最低点时,既不是偏差最小的模型,也不是方差最小的模型,而是两者兼顾的最优模型,这才是我们选择模型的目标.

# 回归问题机器学习模型的评价指标

前面讲到了很多根据模型训练误差来挑选模型的思想,但是挑选模型除了训练误差之外,还有很多其他的指标也常常用于模型评价中,回归问题要解决的是连续变量的预测问题,一般用于评价回归问题模型好坏的指标有均方误差(MSE)均绝对误差(MAE)可决系数(R2).假设回归问题标签的真实值为y模型预测值为widehaty样本的数量为n标签真实值的均值为yba不同的回归模型评价指标如下

## 均方误差

均方误差是最常用的回归模型评价,使用平方项来度量预测值与真实值之间的区别,也被称为L2损失函数,公式为
$$
MSE(y,\widehat{y})=\frac{1}{n}\sum^{n-1}_{i=0}(y_i-\widehat{y}_i)^2
$$

## 均绝对误差

均绝对误差使用绝对值来度量预测值与真实值之间的区别,也被称为L1损失函数,公式为
$$
MAE(y,\widehat{y})=\frac{1}{n}\sum^{n-1}_{i=0}|y_i-\widehat{y}_i|
$$

## 可决系数

可决系数代表着模型能够解决真实预测标签的方差占比,其计算公式为
$$
R^2(y,\widehat{y})=1-\frac{\sum^{n}_{i=1}(y_i-\widehat{y}_i)^2}{\sum^{n}_{i=1}(y_i-\overline{y})^2}
$$
当R2值为1时,说明预测值与真实值完全相同,需要说明的是,R2也可能小于0,这是因为模型的分子度量这预测值和真实值之间的误差,而分母则度量着预测值和样本均值之间的误差.当预测模型的结果特别离谱预测结果还没有样本均值好,这个指标会出现负值

## Python实现

可以直接调用sklearn库中的以下函数来实现以上评价指标的计算

```python
sklearn.metrics.mean_squared_error(y_true,y_pred)
sklearn.metrics.mean_absolute_error(y_true,y_pred)
sklearn.metrics.r2_score(y_true,y_pred)
```

y_true 数据集标签的真实值

y_pred 数据集标签的预测值

# 机器学习的超参数调校

在机器学习的建模过程中,一般需要把已有的数据样本划分为三个部分:训练集 验证集和测试集 训练集是用来拟合数据初步建立模型的样本 验证集可以看成伪测试集是用来调整模型超参数hyperparameters的样本.测试集是最终评估不同模型在样本外表现得样本

可以想象一个这样的场景,你是一名高中生物老师,目前你需要在全班学生中选出一名学生,代表班级参加全国生物竞赛,为班级争取荣誉.你手上得教学资料有过去20年得生物竞赛真题,你会怎么做呢?首先你会让全班同学学习10年得生物竞赛真题,然后看不同的学生对历年生物竞赛真题掌握程度怎么样.随后,你重点注意那些上课表现好 对10年真题回答正确率高的学生.随后 你会进一步在这些学生中举行5次额外测试,你会把之前没有教过学生的5年真题发给大家,看看大家对于没有见过的题目掌握程度如何,并且你也会给学生讲解这些真题,帮助大家继续进步,这样还可以帮助你排除掉一些依靠死记硬背 不会举一反三的学生 最后 你会基于最后的5年真题举办5场模拟考试 在最后的这部分学生中挑选5长模拟考试平均成绩最好的学生 参加最后的全国生物竞赛.

上面挑选学生参加生物竞赛的过程 其实跟我们挑选一个正确的机器学习模型非常类似 为了让我们的模型能够在未来新的样本上取得优异的表现,需要想办法增强模型的泛化能力,尽可能地降低模型的泛化误差 为此,首先可以把所有的数据按照2:1:1切成3份.1/2的样本作为训练集用来训练和拟合模型,这部分可以理解为我们前面说的前10年生物竞赛真题,1/4样本作为验证集,作为我们用来调超参数的样本,这部分可以理解成举行5次额外测试.1/4的样本作为测试集,作为我们比较不同模型泛化误差的样本基础,这部分可以理解成基于最后的5年真题举办的5场模拟考试.需要提醒的是,一般来说,训练集 验证集和测试集三这个应该互斥,即训练集的样本 验证集的样本和测试样本都是不同的 也就是说,我们认为最终的全国生物竞赛是不会出现原题的 希望学生参加的模拟考试题目也不要出现教学时的原题

验证集的设置方法根据样本的特点不同,一般有固定交叉验证,k折交叉验证,时间序列交叉验证三种.

## 固定交叉验证

## k折交叉验证

## 超参数的选取:网格搜索与随机搜索